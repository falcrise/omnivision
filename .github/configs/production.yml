# Production Configuration  
name: production-config

gcp:
  project_id: "falcon-deeptech-ai-stuff"  # Update with your production project
  region: "asia-southeast1"
  
model:
  name: "smolvlm-instruct"
  display_name: "SmolVLM-Instruct-Production"
  huggingface_id: "HuggingFaceTB/SmolVLM-Instruct"
  
deployment:
  endpoint_name: "smolvlm-instruct-prod-endpoint"
  machine_type: "g2-standard-12"  # Larger for production
  accelerator_type: "NVIDIA_L4"
  accelerator_count: 1
  min_replica_count: 2  # Higher availability
  max_replica_count: 5
  
container:
  uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.2-1.py310"
  environment_variables:
    TASK: "image-text-to-text"
    AIP_HEALTH_ROUTE: "/health"
    AIP_PREDICT_ROUTE: "/predict"
    AIP_HTTP_PORT: "8080"
    LOG_LEVEL: "INFO"
